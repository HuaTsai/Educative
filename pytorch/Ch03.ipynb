{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c252a9-1c42-42c7-80d6-436690780bfa",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fd627c-ebb8-4cee-9ce9-04a96d2cc819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[-1.7296, -0.0713, -0.8480,  0.7516],\n",
      "         [-0.2690, -0.7551, -1.0189, -2.1235],\n",
      "         [ 0.5198, -0.5778, -0.7505, -0.8211]],\n",
      "\n",
      "        [[ 0.0798,  1.3242, -0.4487, -1.1434],\n",
      "         [ 0.2923, -2.3548,  0.3108,  0.0164],\n",
      "         [-0.2069, -0.7507,  1.1054, -3.1943]]])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# scalar, vector, matrix, tensor\n",
    "scalar = torch.tensor(3.14159)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "matrix = torch.ones((2, 3), dtype=torch.float)\n",
    "tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(tensor)\n",
    "\n",
    "# size, shape\n",
    "print(tensor.size())\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfb8834-4557-4e12-9f80-35ffbd4f8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# view: share memory\n",
    "same_matrix = matrix.view(1, 6)\n",
    "same_matrix[0, 0] = 0\n",
    "print(matrix)\n",
    "print(same_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff28105-bb54-4a7f-911e-951dfc75e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# clone: copy memory, new_tensor: copy but not recommend\n",
    "# matrix2 = matrix.new_tensor(matrix.view(1, 6))  # not recommend\n",
    "matrix2 = matrix.view(1, 6).clone().detach()\n",
    "matrix2[0, 0] = 1\n",
    "print(matrix)\n",
    "print(matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f913c3-c22f-4d8a-bf4b-220b3b657ea0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99af2aba-c592-4219-85ab-7ec3ef86dfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3745],\n",
      "        [0.9507],\n",
      "        [0.7320],\n",
      "        [0.5987],\n",
      "        [0.1560]], dtype=torch.float64)\n",
      "float64 torch.float64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x_train = np.random.rand(5, 1)\n",
    "\n",
    "# as_tensor: share memory\n",
    "# tensor: always create new tensor\n",
    "x_train_tensor = torch.as_tensor(x_train)\n",
    "print(x_train_tensor)\n",
    "print(x_train.dtype, x_train_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3cc153-f523-4cfe-b4d3-0686feeca117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000],\n",
      "        [0.9507],\n",
      "        [0.7320],\n",
      "        [0.5987],\n",
      "        [0.1560]], dtype=torch.float64)\n",
      "tensor([[0.3745],\n",
      "        [0.9507],\n",
      "        [0.7320],\n",
      "        [0.5987],\n",
      "        [0.1560]])\n"
     ]
    }
   ],
   "source": [
    "# float(), float64 -> float32\n",
    "x_train_tensor_float = x_train_tensor.float()  # copy memory\n",
    "x_train[0, 0] = 2\n",
    "print(x_train_tensor)  # share: 2 appears\n",
    "print(x_train_tensor_float)  # copy: 2 not appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1c9d24-9074-4f65-866f-9ce3d08b6682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012]\n",
      " [0.9507143 ]\n",
      " [3.        ]\n",
      " [0.5986585 ]\n",
      " [0.15601864]]\n"
     ]
    }
   ],
   "source": [
    "# numpy: share memory\n",
    "x_train_numpy = x_train_tensor_float.numpy()\n",
    "x_train_tensor_float[2, 0] = 3\n",
    "print(x_train_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5149898c-39d3-4d92-b3af-74a8fb6a0fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "print(torch.cuda.is_available())\n",
    "n_gpu = torch.cuda.device_count()\n",
    "for i in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738d62af-eaab-46b9-9053-6f4045d2e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000],\n",
      "        [0.9507],\n",
      "        [0.7320],\n",
      "        [0.5987],\n",
      "        [0.1560]], device='cuda:0')\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# GPU tensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpu_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "print(gpu_tensor)\n",
    "print(type(x_train), type(gpu_tensor), gpu_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8057b9-2b78-4f7f-9205-27d08df42c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.        ]\n",
      " [0.9507143 ]\n",
      " [0.7319939 ]\n",
      " [0.5986585 ]\n",
      " [0.15601864]]\n"
     ]
    }
   ],
   "source": [
    "# back to CPU\n",
    "# back_cpu = gpu_tensor.numpy()  # okay if tensor is not on gpu\n",
    "back_cpu = gpu_tensor.cpu().numpy()\n",
    "print(back_cpu)\n",
    "\n",
    "# Summary: GPU -> to(device), CPU -> cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66acd02-3e3f-4471-b830-2b931bd4a460",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2aa67af-6f7b-46f9-a86a-001909d657ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
      "tensor([0.2345], device='cuda:0', grad_fn=<ToCopyBackward0>) tensor([0.2303], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([-1.1229], device='cuda:0', requires_grad=True) tensor([-0.1863], device='cuda:0', requires_grad=True)\n",
      "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# requires_grad: True -> gradient, False -> no gradient\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Attempt I: CPU\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(b, w)\n",
    "\n",
    "# Attempt II: not work\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(b, w)\n",
    "\n",
    "# Attempt III: work, too verbose\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, dtype=torch.float).to(device)\n",
    "b.requires_grad_()  # in pytorch, suffix _ means in-place operation\n",
    "w.requires_grad_()\n",
    "print(b, w)\n",
    "\n",
    "# Attempt IV: work, concise and recommended\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70efe29-c743-422a-8494-f15d7c25d581",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c7d153-2b3a-48fc-8095-daeec04c3963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True\n",
      "False False\n",
      "tensor([-3.3881], device='cuda:0') tensor([-1.9439], device='cuda:0')\n",
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1)\n",
    "y = true_w * x + true_b + np.random.randn(N, 1) * 0.1\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[:int(N * 0.8)]\n",
    "val_idx = idx[int(N * 0.8):]\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "yhat = w * x_train_tensor + b\n",
    "error = yhat - y_train_tensor\n",
    "loss = (error ** 2).mean()\n",
    "loss.backward()\n",
    "print(error.requires_grad, yhat.requires_grad, w.requires_grad, b.requires_grad)\n",
    "print(y_train_tensor.requires_grad, x_train_tensor.requires_grad)\n",
    "print(b.grad, w.grad)\n",
    "\n",
    "# no_grad: tells PyTorch not to track gradients\n",
    "lr = 0.1\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "for epoch in range(1000):\n",
    "    yhat = w * x_train_tensor + b\n",
    "    error = yhat - y_train_tensor\n",
    "    loss = (error ** 2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():  # Key: 1. no_grad, 2. inplace operation\n",
    "        b -= lr * b.grad\n",
    "        w -= lr * w.grad\n",
    "    b.grad.zero_()  # prevent default gradient accumulation\n",
    "    w.grad.zero_()\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d1b57-f15d-4cac-a1f4-44c58ed7d4a8",
   "metadata": {},
   "source": [
    "## Dynamic Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf9a854-9f24-45dd-8098-29f73e8cb3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"283pt\"\n",
       " viewBox=\"0.00 0.00 222.00 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-279 218,-279 218,4 -4,4\"/>\n",
       "<!-- 126470350872704 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>126470350872704</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n",
       "</g>\n",
       "<!-- 126470209320320 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>126470209320320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 126470209320320&#45;&gt;126470350872704 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>126470209320320&#45;&gt;126470350872704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 126470156098608 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>126470156098608</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 126470156098608&#45;&gt;126470209320320 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>126470156098608&#45;&gt;126470209320320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-121.98C67.69,-114.23 80.01,-102.58 89.97,-93.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-95.59 97.34,-86.17 87.67,-90.5 92.48,-95.59\"/>\n",
       "</g>\n",
       "<!-- 126470547559168 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>126470547559168</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-202 0,-202 0,-183 101,-183 101,-202\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 126470547559168&#45;&gt;126470156098608 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>126470547559168&#45;&gt;126470156098608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-182.79C50.5,-174.6 50.5,-162.06 50.5,-151.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.24 50.5,-141.24 47,-151.24 54,-151.24\"/>\n",
       "</g>\n",
       "<!-- 126470350868304 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>126470350868304</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-275 23.5,-275 23.5,-244 77.5,-244 77.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 126470350868304&#45;&gt;126470547559168 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>126470350868304&#45;&gt;126470547559168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-243.75C50.5,-234.39 50.5,-222.19 50.5,-212.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-212.02 50.5,-202.02 47,-212.02 54,-212.02\"/>\n",
       "</g>\n",
       "<!-- 126470156098800 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>126470156098800</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-141 113,-141 113,-122 214,-122 214,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 126470156098800&#45;&gt;126470209320320 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>126470156098800&#45;&gt;126470209320320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-121.98C146,-114.23 133.47,-102.58 123.32,-93.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-90.42 115.82,-86.17 120.76,-95.54 125.53,-90.42\"/>\n",
       "</g>\n",
       "<!-- 126470350871664 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>126470350871664</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-208 136.5,-208 136.5,-177 190.5,-177 190.5,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 126470350871664&#45;&gt;126470156098800 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>126470350871664&#45;&gt;126470156098800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-176.92C163.5,-169.22 163.5,-159.69 163.5,-151.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-151.25 163.5,-141.25 160,-151.25 167,-151.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x730620ba9be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = w * x_train_tensor + b\n",
    "from torchviz import make_dot\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728ce56-1896-4877-9c71-d7a55fc766ca",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14fc6707-f370-427a-bc56-a78f5fc77aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "lr = 0.1\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "optimizer = optim.SGD([b, w], lr=0.1)\n",
    "print(optimizer)\n",
    "for epoch in range(1000):\n",
    "    yhat = w * x_train_tensor + b\n",
    "    error = yhat - y_train_tensor\n",
    "    loss = (error ** 2).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()  # Here is batch gradient descent, not its name SGD\n",
    "    optimizer.zero_grad()\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09beb72-d39b-4160-b263-490325dafac6",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "782c8367-5916-4d71-9111-7f3de4411ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss()\n",
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
      "0.008044656\n",
      "0.008044656366109848\n",
      "0.008044656366109848\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "lr = 0.1\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "optimizer = optim.SGD([b, w], lr=0.1)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "print(loss_fn)\n",
    "for epoch in range(1000):\n",
    "    yhat = w * x_train_tensor + b\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "print(b, w)\n",
    "# we can see scalar loss via the following methods\n",
    "print(loss.detach().cpu().numpy())\n",
    "print(loss.item())\n",
    "print(loss.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845cf13-38bd-4389-a30d-0c2118bc85eb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5473a69-4ee4-44c2-83dd-25ff16903d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([0.3367], requires_grad=True), Parameter containing:\n",
      "tensor([0.1288], requires_grad=True)]\n",
      "OrderedDict({'b': tensor([0.3367]), 'w': tensor([0.1288])})\n"
     ]
    }
   ],
   "source": [
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.w = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.b + self.w * x\n",
    "\n",
    "dummy = ManualLinearRegression()\n",
    "print(list(dummy.parameters()))\n",
    "print(dummy.state_dict())  # contains learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91b93d3-59e8-4dfd-a13a-862c946e3b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "print(optimizer.state_dict())  # contains hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08559a31-5b49-4801-945b-6576652dbb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'b': tensor([1.0235], device='cuda:0'), 'w': tensor([1.9690], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "torch.manual_seed(42)\n",
    "model = ManualLinearRegression().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss(reduction='mean')  # higher-order function\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # training mode, good practice to put in the loop\n",
    "    yhat = model(x_train_tensor)  # not call forward() so hook works\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284d59e-1d74-41d4-8370-b3ef9c7241e6",
   "metadata": {},
   "source": [
    "## Model Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fa8ce0b-1ac5-42ac-9279-e5839fdf9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'weight': tensor([[-0.2191]]), 'bias': tensor([0.2018])})\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(1, 1)\n",
    "print(linear.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943e1980-4fc2-4596-bbef-36ff9b41839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.4869]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5873], device='cuda:0', requires_grad=True)]\n",
      "OrderedDict({'linear.weight': tensor([[-0.4869]], device='cuda:0'), 'linear.bias': tensor([0.5873], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        self.linear(x)  # not self.linear.forward\n",
    "dummy = MyLinearRegression().to(device)\n",
    "print(list(dummy.parameters()))\n",
    "print(dummy.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38076b44-d7b8-4db9-8f9e-975ba1c5c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'0.weight': tensor([[0.8815]], device='cuda:0'), '0.bias': tensor([-0.7336], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "# For simple model in this example, we may use Sequential\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f04c0-49b9-4cde-ade8-afd8e3a99d74",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46408714-c1f6-4215-b73b-5cf79d7c66bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'0.weight': tensor([[ 0.5018,  0.1081,  0.4266],\n",
      "        [ 0.0782,  0.2784, -0.0815],\n",
      "        [ 0.4451,  0.0853, -0.2695],\n",
      "        [ 0.1472, -0.2660, -0.0677],\n",
      "        [-0.2345,  0.3830, -0.4557]], device='cuda:0'), '0.bias': tensor([-0.2662, -0.1630, -0.3471,  0.0545, -0.5702], device='cuda:0'), '1.weight': tensor([[ 0.4039, -0.3799,  0.3453,  0.0744, -0.1452]], device='cuda:0'), '1.bias': tensor([0.2764], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(3, 5), nn.Linear(5, 1)).to(device)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d1a2cd6-f907-40be-9cc3-a157792d9dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (layer1): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('layer1', nn.Linear(3, 5))\n",
    "model.add_module('layer2', nn.Linear(5, 1))\n",
    "print(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b03085-8985-4ccf-9678-405f129f32ee",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b5cf2e0-357b-4626-8351-b1f0523c3eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting datagen.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile datagen.py\n",
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1)\n",
    "y = true_b + true_w * x + (.1 * np.random.randn(N, 1))\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[:int(N*.8)]\n",
    "val_idx = idx[int(N*.8):]\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2789996f-5a87-488c-ac83-78805bd779ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting datapre_v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile datapre_v0.py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dcba43f-ccb5-415c-8789-08f55c32ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_v0.py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.1\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa8382b3-cf79-448e-af06-a420d4d1048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_v0.py\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    yhat = model(x_train_tensor)\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba99a9b6-ffa1-4efb-acaa-b38baf3f2310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'0.weight': tensor([[1.9690]], device='cuda:0'), '0.bias': tensor([1.0235], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "%run -i datagen.py\n",
    "%run -i datapre_v0.py\n",
    "%run -i model_v0.py\n",
    "%run -i train_v0.py\n",
    "print(model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
